<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><style>body {
  max-width: 980px;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 45px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable,
.markdown-body .highlighttable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr,
.markdown-body .highlighttable {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite,
.markdown-body .highlighttable pre,
.markdown-body .highlighttable div.highlight {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td,
.markdown-body .highlighttable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headerlink {
  font: normal 400 16px fontawesome-mini;
  vertical-align: middle;
  margin-left: -16px;
  float: left;
  display: inline-block;
  text-decoration: none;
  opacity: 0;
  color: #333;
}

.markdown-body .headerlink:focus {
  outline: none;
}

.markdown-body h1 .headerlink {
  margin-top: 0.8rem;
}

.markdown-body h2 .headerlink,
.markdown-body h3 .headerlink {
  margin-top: 0.6rem;
}

.markdown-body h4 .headerlink {
  margin-top: 0.2rem;
}

.markdown-body h5 .headerlink,
.markdown-body h6 .headerlink {
  margin-top: 0;
}

.markdown-body .headerlink:hover,
.markdown-body h1:hover .headerlink,
.markdown-body h2:hover .headerlink,
.markdown-body h3:hover .headerlink,
.markdown-body h4:hover .headerlink,
.markdown-body h5:hover .headerlink,
.markdown-body h6:hover .headerlink {
  opacity: 1;
  text-decoration: none;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  border-radius: 3px;
}

.markdown-body code:not(.highlight):not(.codehilite), .markdown-body samp {
  background-color: rgba(0,0,0,0.04);
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite,
.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body .highlight pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
}

.markdown-body .codehilite,
.markdown-body .highlight,
.markdown-body pre {
  border-radius: 3px;
}

.markdown-body :not(.highlight) > pre {
  background-color: #f7f7f7;
}

.markdown-body .codehilite pre,
.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* MultiMarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px fontawesome-mini;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\e157';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

.markdown-body diagram-div, .markdown-body div.uml-sequence-diagram, .markdown-body, div.uml-flowchart {
  overflow: auto;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><style>/*GitHub*/
.highlight {background-color:#f7f7f7;color:#333333;}
.highlight .hll {background-color:#ffffcc;}
.highlight .c{color:#999988;font-style:italic}
.highlight .err{color:#a61717;background-color:#e3d2d2}
.highlight .k{font-weight:bold}
.highlight .o{font-weight:bold}
.highlight .cm{color:#999988;font-style:italic}
.highlight .cp{color:#999999;font-weight:bold}
.highlight .c1{color:#999988;font-style:italic}
.highlight .cs{color:#999999;font-weight:bold;font-style:italic}
.highlight .gd{color:#000000;background-color:#ffdddd}
.highlight .ge{font-style:italic}
.highlight .gr{color:#aa0000}
.highlight .gh{color:#999999}
.highlight .gi{color:#000000;background-color:#ddffdd}
.highlight .go{color:#888888}
.highlight .gp{color:#555555}
.highlight .gs{font-weight:bold}
.highlight .gu{color:#800080;font-weight:bold}
.highlight .gt{color:#aa0000}
.highlight .kc{font-weight:bold}
.highlight .kd{font-weight:bold}
.highlight .kn{font-weight:bold}
.highlight .kp{font-weight:bold}
.highlight .kr{font-weight:bold}
.highlight .kt{color:#445588;font-weight:bold}
.highlight .m{color:#009999}
.highlight .s{color:#dd1144}
.highlight .n{color:#333333}
.highlight .na{color:teal}
.highlight .nb{color:#0086b3}
.highlight .nc{color:#445588;font-weight:bold}
.highlight .no{color:teal}
.highlight .ni{color:purple}
.highlight .ne{color:#990000;font-weight:bold}
.highlight .nf{color:#990000;font-weight:bold}
.highlight .nn{color:#555555}
.highlight .nt{color:navy}
.highlight .nv{color:teal}
.highlight .ow{font-weight:bold}
.highlight .w{color:#bbbbbb}
.highlight .mf{color:#009999}
.highlight .mh{color:#009999}
.highlight .mi{color:#009999}
.highlight .mo{color:#009999}
.highlight .sb{color:#dd1144}
.highlight .sc{color:#dd1144}
.highlight .sd{color:#dd1144}
.highlight .s2{color:#dd1144}
.highlight .se{color:#dd1144}
.highlight .sh{color:#dd1144}
.highlight .si{color:#dd1144}
.highlight .sx{color:#dd1144}
.highlight .sr{color:#009926}
.highlight .s1{color:#dd1144}
.highlight .ss{color:#990073}
.highlight .bp{color:#999999}
.highlight .vc{color:teal}
.highlight .vg{color:teal}
.highlight .vi{color:teal}
.highlight .il{color:#009999}
.highlight .gc{color:#999;background-color:#EAF2F5}
</style><title>README</title></head><body><article class="markdown-body"><h1 id="qgtdb">Q.GTDB<a class="headerlink" href="#qgtdb" title="Permanent link"></a></h1>
<h2 id="results-executive-summary">Results executive summary&hellip;<a class="headerlink" href="#results-executive-summary" title="Permanent link"></a></h2>
<p>I&rsquo;ve estimated a lot of models below. The main question is how they perform on the full GTDB dataset, and here&rsquo;s a table for that&hellip;</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Likelihood</th>
<th>AIC</th>
<th>Time</th>
<th>Dataset</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q.bacteria_phylum_1</td>
<td>-131190357.878285</td>
<td>262629875.756571</td>
<td>1866.073</td>
<td>QBp1G.raxml.log</td>
</tr>
<tr>
<td>Q.bacteria_class_1</td>
<td>-131099420.890135</td>
<td>262448001.780271</td>
<td>1442.474</td>
<td>Q.bacteria_class_1_G_reduced_aln.raxml.log</td>
</tr>
<tr>
<td>LG</td>
<td>-130592049.145638</td>
<td>261433258.291277</td>
<td>3785.556</td>
<td>LGG.raxml.log</td>
</tr>
<tr>
<td>Q.bacteria_phylum_1</td>
<td>-1088000564.208966</td>
<td>2176250288.417933</td>
<td>17965.016</td>
<td>QBp1G_full.raxml.log</td>
</tr>
<tr>
<td>Q.bacteria_phylum_1</td>
<td>-1086808724.440440</td>
<td>2173866608.880880</td>
<td>12427.577</td>
<td>Q.bacteria_class_1_G_full_aln.raxml.log</td>
</tr>
<tr>
<td>Q.bacteria_phylum_1</td>
<td>-1081479614.701307</td>
<td>2163208389.402613</td>
<td>20892.610</td>
<td>LGG_full.raxml.log</td>
</tr>
<tr>
<td>Q.bacteria_phylum_1</td>
<td>-1078809634.619930</td>
<td>2157868429.239860</td>
<td>11799.372</td>
<td>Q.GTDB_sub_5k_G_full_aln.raxml.log</td>
</tr>
</tbody>
</table>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link"></a></h2>
<p>The aim for this matrix is to estimate a single amino acid matrix for the GTDB dataset.</p>
<p>The dataset comprises 120 genes, each for ~85K taxa. The main challenges are that this is just too many taxa. So we need to come up with sensible ways of estimating matrices from a subset of the taxa. I will use a lot of the suggestions from <a class="magiclink magiclink-github magiclink-repository" href="https://github.com/roblanf/Q.GTDB" title="GitHub Repository: roblanf/Q.GTDB">roblanf/Q.GTDB</a>, with some modifications.</p>
<h2 id="getting-set-up">Getting set up<a class="headerlink" href="#getting-set-up" title="Permanent link"></a></h2>
<p>Install and activate the conda environment like so:</p>
<div class="highlight"><pre>conda env create -f env.yml
conda activate qgtdb
</pre></div>

<h2 id="input-data">Input data<a class="headerlink" href="#input-data" title="Permanent link"></a></h2>
<p>For the purposes of this work, the 120 gene alignments are in:</p>
<div class="highlight"><pre>/alignments
</pre></div>

<p>these aren&rsquo;t on GitHub - they&rsquo;re too big.</p>
<p>The pre-estimated tree for these data (estimated in FastTree using an LG model) is:</p>
<div class="highlight"><pre>gtdb_r207_bac120_unscaled.decorated.tree
</pre></div>

<p>there is also a &lsquo;clean&rsquo; version of this tree, without the decorations:</p>
<div class="highlight"><pre>r207_original_clean.tree
</pre></div>

<p>finally, there&rsquo;s a big taxonomy table here:</p>
<div class="highlight"><pre>gtdb_r207_bac120_curation_taxonomy.tsv
</pre></div>

<p>This file is a bit annoying. It looks like this:</p>
<div class="highlight"><pre>G009834515  d__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Pseudomonadales;f__Pseudomonadaceae;g__Pseudomonas_E;s__Pseudomonas_E sp009834515
G900187605  d__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Pseudomonadales;f__Pseudomonadaceae;g__Pseudomonas_E;s__Pseudomonas_E sp900187605
G013433315  d__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Pseudomonadales;f__Pseudomonadaceae;g__Pseudomonas_E;s__Pseudomonas_E crudilactis
G018138145  d__Bacteria;p__Proteobacteria;c__Gammaproteobacteria;o__Pseudomonadales;f__Pseudomonadaceae;g__Pseudomonas_E;s__Pseudomonas_E koreensis_A
</pre></div>

<p>So we first process it into a taxonomy file that&rsquo;s tab delimited for easier processing:</p>
<div class="highlight"><pre>awk &#39;BEGIN { FS=OFS=&quot;\t&quot; } { gsub(&quot;;&quot;, &quot;\t&quot;, $2) } 1&#39; input.tsv &gt; output.tsv
</pre></div>

<p>now it looks like this:</p>
<div class="highlight"><pre>G009834515  d__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Pseudomonadaceae g__Pseudomonas_E    s__Pseudomonas_E sp009834515
G900187605  d__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Pseudomonadaceae g__Pseudomonas_E    s__Pseudomonas_E sp900187605
G013433315  d__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Pseudomonadaceae g__Pseudomonas_E    s__Pseudomonas_E crudilactis
G018138145  d__Bacteria p__Proteobacteria   c__Gammaproteobacteria  o__Pseudomonadales  f__Pseudomonadaceae g__Pseudomonas_E    s__Pseudomonas_E koreensis_A
</pre></div>

<h2 id="taxonomy-summary">Taxonomy summary<a class="headerlink" href="#taxonomy-summary" title="Permanent link"></a></h2>
<p>in R&hellip;</p>
<div class="highlight"><pre>library(tidyverse)
tax &lt;- read_delim(&quot;taxonomy.tsv&quot;, delim=&quot;\t&quot;, col_names = FALSE)
names(tax) &lt;- c(&quot;id&quot;, &quot;clade&quot;, &quot;phylum&quot;, &quot;class&quot;, &quot;order&quot;, &quot;family&quot;, &quot;genus&quot;, &quot;species&quot;)

unique_counts &lt;- tax %&gt;%
    gather(column, value) %&gt;%                # Convert data to long format
    group_by(column) %&gt;%                     # Group by column names
    summarise(unique_entries = n_distinct(value)) %&gt;% # Count unique values
    arrange(unique_entries)
</pre></div>

<p>Gives:</p>
<div class="highlight"><pre>&gt; unique_counts
# A tibble: 8 × 2
  column  unique_entries
  &lt;chr&gt;            &lt;int&gt;
1 clade                1
2 phylum             169
3 class              428
4 order             1460
5 family            3650
6 genus            15342
7 id               62291
8 species          62291
</pre></div>

<h3 id="assessing-the-distribution-of-gaps">Assessing the distribution of gaps<a class="headerlink" href="#assessing-the-distribution-of-gaps" title="Permanent link"></a></h3>
<p>Since we want to estimate substitutino models, we don&rsquo;t want to include genomes with too many gaps. Let&rsquo;s take a look at that first.</p>
<div class="highlight"><pre>gtdb_r207_bac120_full.faa
</pre></div>

<p>I can then calculate gap proportions like this (for sure there are quicker and smarter ways using actual software, but I was about to go home for the evening, so this sufficed):</p>
<div class="highlight"><pre>awk &#39;/^&gt;/ {if (seq) {print id, seq}; id=substr($1, 2); seq=&quot;&quot;; next} {seq=seq$0} END {print id, seq}&#39; gtdb_r207_bac120_full.faa | 
while read -r id seq; do
    total_length=$(echo -n &quot;$seq&quot; | wc -c)
    gap_count=$(echo -n &quot;$seq&quot; | sed &#39;s/[^-]//g&#39; | wc -c)
    gap_proportion=$(echo &quot;scale=2; $gap_count / $total_length&quot; | bc -l)
    echo -e &quot;$id\t$gap_proportion&quot;
done &gt; gaps.tsv
</pre></div>

<p>We can look at the distribution:</p>
<div class="highlight"><pre>gaps &lt;- read_delim(&quot;gaps.tsv&quot;, delim=&quot;\t&quot;, col_names = c(&quot;id&quot;, &quot;proportion_gaps&quot;))
ggplot(gaps, aes(x = proportion_gaps)) + geom_histogram(bins=80)
</pre></div>

<p>Let&rsquo;s add the gaps to the big dataset:</p>
<div class="highlight"><pre>tax &lt;- tax %&gt;%
  inner_join(gaps, by = &quot;id&quot;)
</pre></div>

<p>Let&rsquo;s look at the proportion of sequences with fewer gaps than each threshold:</p>
<div class="highlight"><pre>results &lt;- map_dfr(seq(0, 1, by = 0.01), function(threshold) {
  proportion_below_threshold &lt;- mean(tax$proportion_gaps &lt; threshold)
  tibble(threshold = threshold, proportion_below = proportion_below_threshold)
})

head(results, 40)

ggplot(results, aes(x = threshold, y = proportion_below)) +
  geom_point() +
  geom_line()
</pre></div>

<p>This shows that we lose half the data by removing everything with &gt;10% gaps. Let&rsquo;s check how different thresholds would affect the number of phyla and other ranks we&rsquo;d have.</p>
<div class="highlight"><pre>thresholds &lt;- seq(100, 0, by = -10)

for (thresh in thresholds) {
  col_name &lt;- paste0(&quot;unique_entries_&quot;, thresh)

  temp_counts &lt;- tax %&gt;%
    filter(proportion_gaps &lt;= (thresh / 100)) %&gt;%
    gather(column, value, -id, -proportion_gaps) %&gt;%
    group_by(column) %&gt;%
    summarise(!!col_name := n_distinct(value))

  unique_counts &lt;- left_join(unique_counts, temp_counts, by = &quot;column&quot;)
}

percentage_retained &lt;- unique_counts[,3:12] / unique_counts$unique_entries

rownames(percentage_retained) &lt;- unique_counts$column
</pre></div>

<p>This shows us what proportion of each rank (phylum, class, etc) is retained with different gap cutoffs:</p>
<div class="highlight"><pre>&gt; percentage_retained
        unique_entries_100 unique_entries_90 unique_entries_80 unique_entries_70 unique_entries_60 unique_entries_50 unique_entries_40 unique_entries_30 unique_entries_20 unique_entries_10
clade                    1                 1                 1         1.0000000         1.0000000         1.0000000         1.0000000         1.0000000         1.0000000         1.0000000
phylum                   1                 1                 1         1.0000000         1.0000000         0.9881657         0.9822485         0.9644970         0.8579882         0.5798817
class                    1                 1                 1         1.0000000         1.0000000         0.9953271         0.9836449         0.9485981         0.8247664         0.5490654
order                    1                 1                 1         1.0000000         1.0000000         0.9952055         0.9712329         0.9082192         0.7664384         0.4910959
family                   1                 1                 1         0.9997260         0.9986301         0.9901370         0.9602740         0.8660274         0.7216438         0.4646575
genus                    1                 1                 1         0.9997393         0.9986312         0.9866380         0.9431626         0.8473472         0.7088385         0.4561987
id                      NA                NA                NA                NA                NA                NA                NA                NA                NA                NA
species                  1                 1                 1         0.9998234         0.9983465         0.9822286         0.9328153         0.8389013         0.6966335         0.4836814
</pre></div>

<p>So a sensible cutoff here is to only keep taxa with &lt;20% gaps - this means we keep ~70% of the species, and more than 80% of the phyla and classes are still represented.</p>
<h3 id="assessing-long-branches">Assessing long branches<a class="headerlink" href="#assessing-long-branches" title="Permanent link"></a></h3>
<p>We  also need to assess if any taxa are on crazy long branches. This can happen if the genomes are poorly sequenced or aligned, and can be a big problem for estimating the Q matrix. So let&rsquo;s use TreeShrink for this.</p>
<div class="highlight"><pre>run_treeshrink.py -t r207_original_clean.tree
</pre></div>

<p>Now let&rsquo;s look at what happened, by analysing the tree before and after:</p>
<div class="highlight"><pre>scripts/tree_length.py r207_original_clean.tree
mv branch_length_histogram.png before_pruning.png
scripts/tree_length.py r207_original_clean_treeshrink/output.tree
mv branch_length_histogram.png after_pruning.png
</pre></div>

<p>Before</p>
<p><img alt="" src="/Users/roblanfear/Documents/GitHub/Q.GTDB/Q.GTDB/before_pruning.png" /></p>
<p>After</p>
<p><img alt="" src="/Users/roblanfear/Documents/GitHub/Q.GTDB/Q.GTDB/after_pruning.png" /></p>
<p>The total tree length dropped from 6908.397739999869 to 6899.0687299998635. </p>
<p>Treeshrink removed 18 branches, by removing the following taxa:</p>
<div class="highlight"><pre>G002325765      
G001730065      
G002682985      
G000508245      
G000277795      
G000319365      
G000281235      
G000477415      
G000179035      
G002135175      
G000238995 
G000200735       
G001645765      
G902712995      
G000008205      
G000815065      
G900660545      
G001951355      
G000218525
</pre></div>

<p>We can look at them like this</p>
<div class="highlight"><pre>treeshrink &lt;- c(&quot;G002325765&quot;,&quot;G001730065&quot;,&quot;G002682985&quot;,&quot;G000508245&quot;,&quot;G000277795&quot;,&quot;G000319365&quot;,&quot;G000281235&quot;,&quot;G000477415&quot;,&quot;G000179035&quot;,&quot;G002135175&quot;,&quot;G000238995&quot;,&quot;G000200735&quot;,&quot;G001645765&quot;,&quot;G902712995&quot;,&quot;G000008205&quot;,&quot;G000815065&quot;,&quot;G900660545&quot;,&quot;G001951355&quot;,&quot;G000218525&quot;)

tax %&gt;% filter(id %in% treeshrink)
</pre></div>

<div class="highlight"><pre>&gt; tax %&gt;% filter(id %in% treeshrink)
# A tibble: 19 × 9
   id         clade       phylum            class                  order                 family                  genus               species                           proportion_gaps
   &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;             &lt;chr&gt;                  &lt;chr&gt;                 &lt;chr&gt;                   &lt;chr&gt;               &lt;chr&gt;                                       &lt;dbl&gt;
 1 G002682985 d__Bacteria p__Proteobacteria c__Gammaproteobacteria o__Enterobacterales_A f__Enterobacteriaceae_A g__Tremblaya        s__Tremblaya phenacola                       0.62
 2 G001730065 d__Bacteria p__Proteobacteria c__Alphaproteobacteria o__Rickettsiales      f__AB1-6                g__AB1-6            s__AB1-6 sp001730065                         0.52
 3 G002325765 d__Bacteria p__Proteobacteria c__Alphaproteobacteria o__Rickettsiales      f__UBA1459              g__UBA1459          s__UBA1459 sp002325765                       0.66
 4 G900660545 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Metamycoplasmataceae g__Mycoplasmopsis_A s__Mycoplasmopsis_A cynos                    0.34
 5 G000008205 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Metamycoplasmataceae g__Mesomycoplasma   s__Mesomycoplasma hyopneumoniae              0.34
 6 G000815065 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Metamycoplasmataceae g__Mesomycoplasma   s__Mesomycoplasma flocculare                 0.33
 7 G000218525 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Metamycoplasmataceae g__Mesomycoplasma   s__Mesomycoplasma ovipneumoniae_A            0.34
 8 G001951355 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Metamycoplasmataceae g__Mesomycoplasma   s__Mesomycoplasma ovipneumoniae              0.34
 9 G000277795 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_A  s__Eperythrozoon_A wenyonii                  0.56
10 G000508245 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_A  s__Eperythrozoon_A ovis                      0.57
11 G000319365 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_A  s__Eperythrozoon_A haemominutum              0.56
12 G000281235 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_A  s__Eperythrozoon_A haemolamae                0.57
13 G000179035 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_A  s__Eperythrozoon_A suis                      0.54
14 G000477415 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_A  s__Eperythrozoon_A parvum                    0.54
15 G000200735 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_B  s__Eperythrozoon_B haemofelis                0.44
16 G000238995 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_B  s__Eperythrozoon_B haemocanis                0.47
17 G001645765 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_B  s__Eperythrozoon_B haemobos                  0.44
18 G902712995 d__Bacteria p__Firmicutes     c__Bacilli             o__Mycoplasmatales    f__Mycoplasmoidaceae    g__Eperythrozoon_B  s__Eperythrozoon_B haemohominis              0.51
</pre></div>

<p>These are all species with a LOT of gaps, highlighting the issues with these kinds of taxa!</p>
<h3 id="correlation-between-branch-lengths-and-gaps">Correlation between branch lengths and gaps<a class="headerlink" href="#correlation-between-branch-lengths-and-gaps" title="Permanent link"></a></h3>
<p>Let&rsquo;s check to see the scale of the problem. </p>
<p>First we get the terminal branch lengths, then add them to the main tibble</p>
<div class="highlight"><pre>t &lt;- read.tree(&quot;r207_original_clean.tree&quot;)
tip_names &lt;- t$tip.label
terminal_branch_lengths &lt;- t$edge.length[t$edge[, 2] &lt;= length(tip_names)]
tips &lt;- tibble(id = tip_names, branch_length = terminal_branch_lengths)

# add to main tibble
tax &lt;- left_join(tax, tips, by = &quot;id&quot;)
</pre></div>

<p>Now we can plot it out&hellip;</p>
<div class="highlight"><pre>ggplot(tax, aes(x = proportion_gaps, y = branch_length)) +
    geom_boxplot(aes(group = proportion_gaps), size = 0.1, alpha = 0.1) +
    geom_point(data = filter(tax, id %in% treeshrink), 1, colour = &#39;red&#39;)
</pre></div>

<p><img alt="" src="/Users/roblanfear/Documents/GitHub/Q.GTDB/Q.GTDB/bl_plot.png" /></p>
<p>We can see that the treeshrink taxa all have a lot of gaps, and a mild but not alarming tendency for more gaps to be associated with longer branch lengths.</p>
<h2 id="subset-taxa">Subset taxa<a class="headerlink" href="#subset-taxa" title="Permanent link"></a></h2>
<h3 id="subset-by-gaps">Subset by gaps<a class="headerlink" href="#subset-by-gaps" title="Permanent link"></a></h3>
<p>First we&rsquo;ll remove taxa based on our gap threshold</p>
<div class="highlight"><pre>subset = tax %&gt;% 
            filter(proportion_gaps&lt;0.20)
</pre></div>

<h3 id="subset-by-treeshrink">Subset by treeshrink<a class="headerlink" href="#subset-by-treeshrink" title="Permanent link"></a></h3>
<p>Now we can remove the treeshrink taxa</p>
<div class="highlight"><pre>subset = subset %&gt;% 
            filter(!id %in% treeshrink)
</pre></div>

<p>Actually this didn&rsquo;t remove any more taxa - they were already removed based on gaps, as expected from the plot above.</p>
<p>Now let&rsquo;s see what we&rsquo;ve got:</p>
<div class="highlight"><pre>unique_counts &lt;- subset %&gt;%
    gather(column, value) %&gt;%                # Convert data to long format
    group_by(column) %&gt;%                     # Group by column names
    summarise(unique_entries = n_distinct(value)) %&gt;% # Count unique values
    arrange(unique_entries)
</pre></div>

<div class="highlight"><pre>&gt; unique_counts
# A tibble: 9 × 2
  column          unique_entries
  &lt;chr&gt;                    &lt;int&gt;
1 clade                        1
2 proportion_gaps             19
3 phylum                     140
4 class                      343
5 order                     1090
6 family                    2570
7 genus                    10603
8 id                       42385
9 species                  42385
</pre></div>

<h3 id="one-random-genome-per-phylum">One random genome per phylum<a class="headerlink" href="#one-random-genome-per-phylum" title="Permanent link"></a></h3>
<p>Let&rsquo;s start by making three Q matrices, each by selecting a single random ID from every phylum:</p>
<div class="highlight"><pre>sample_phylum_id &lt;- function(data) {
  data %&gt;%
    group_by(phylum) %&gt;%
    sample_n(1) %&gt;%
    ungroup() %&gt;%
    pull(id)
}

phylum_1 &lt;- sample_phylum_id(subset)
phylum_2 &lt;- sample_phylum_id(subset)
phylum_3 &lt;- sample_phylum_id(subset)
</pre></div>

<p>Then lets see how different these are:</p>
<div class="highlight"><pre>common_1_2 &lt;- length(intersect(phylum_1, phylum_2))
common_1_3 &lt;- length(intersect(phylum_1, phylum_3))
common_2_3 &lt;- length(intersect(phylum_2, phylum_3))
</pre></div>

<p>They have 38, 41, and 44 IDs in common, respectively, so the majority (about 100) of the IDs are different between each pair. This is good. If we get very similar matrices with these three lists, that will indicate that the details of the taxon selection didn&rsquo;t matter much.</p>
<p>Let&rsquo;s write out these lists for future usage&hellip;</p>
<div class="highlight"><pre>writeLines(phylum_1, &quot;phylum_1.txt&quot;)
writeLines(phylum_2, &quot;phylum_2.txt&quot;)
writeLines(phylum_3, &quot;phylum_3.txt&quot;)
</pre></div>

<h3 id="one-random-genome-per-class">One random genome per class<a class="headerlink" href="#one-random-genome-per-class" title="Permanent link"></a></h3>
<p>We can also do one random genome per class, like so:</p>
<div class="highlight"><pre>sample_class_id &lt;- function(data) {
  data %&gt;%
    group_by(class) %&gt;%
    sample_n(1) %&gt;%
    ungroup() %&gt;%
    pull(id)
}

class_1 &lt;- sample_class_id(subset)
class_2 &lt;- sample_class_id(subset)
class_3 &lt;- sample_class_id(subset)
</pre></div>

<p>Then lets see how different these are:</p>
<div class="highlight"><pre>common_1_2 &lt;- length(intersect(class_1, class_2))
common_1_3 &lt;- length(intersect(class_1, class_3))
common_2_3 &lt;- length(intersect(class_2, class_3))
</pre></div>

<p>They have ~120 IDs in common, respectively, so the majority (about 200) of the IDs are different between each pair. This is good. </p>
<p>Let&rsquo;s write out these lists for future usage&hellip;</p>
<div class="highlight"><pre>writeLines(class_1, &quot;class_1.txt&quot;)
writeLines(class_2, &quot;class_2.txt&quot;)
writeLines(class_3, &quot;class_3.txt&quot;)
</pre></div>

<h3 id="one-random-genome-per-order">One random genome per order<a class="headerlink" href="#one-random-genome-per-order" title="Permanent link"></a></h3>
<p>We can also do one random genome per order, like so:</p>
<div class="highlight"><pre>sample_order_id &lt;- function(data) {
  data %&gt;%
    group_by(order) %&gt;%
    sample_n(1) %&gt;%
    ungroup() %&gt;%
    pull(id)
}

order_1 &lt;- sample_order_id(subset)
order_2 &lt;- sample_order_id(subset)
order_3 &lt;- sample_order_id(subset)
</pre></div>

<p>Then lets see how different these are:</p>
<div class="highlight"><pre>common_1_2 &lt;- length(intersect(order_1, order_2))
common_1_3 &lt;- length(intersect(order_1, order_3))
common_2_3 &lt;- length(intersect(order_2, order_3))
</pre></div>

<p>They have ~490 IDs in common, respectively, so about half (about 500) of the IDs are different between each pair. This is OK. </p>
<p>Let&rsquo;s write out these lists for future usage&hellip;</p>
<div class="highlight"><pre>writeLines(order_1, &quot;order_1.txt&quot;)
writeLines(order_2, &quot;order_2.txt&quot;)
writeLines(order_3, &quot;order_3.txt&quot;)
</pre></div>

<h2 id="estimate-q-matrices-with-one-random-genome">Estimate Q Matrices with one random genome<a class="headerlink" href="#estimate-q-matrices-with-one-random-genome" title="Permanent link"></a></h2>
<p>Now we estimate a model for each of the taxon lists.</p>
<p>I&rsquo;ll walk through the first one in great detail. The rest are just bash scripts based on the first one!</p>
<h3 id="qphylum_1">Q.phylum_1<a class="headerlink" href="#qphylum_1" title="Permanent link"></a></h3>
<h4 id="1-make-a-folder-and-cd-to-it">1. Make a folder and cd to it<a class="headerlink" href="#1-make-a-folder-and-cd-to-it" title="Permanent link"></a></h4>
<div class="highlight"><pre>mkdir phylum_1
cd phylum_1
cp ../phylum_1.txt .
</pre></div>

<h4 id="2-get-the-subtree">2. Get the subtree<a class="headerlink" href="#2-get-the-subtree" title="Permanent link"></a></h4>
<div class="highlight"><pre>../scripts/get_subtree.py r207_original_clean.tree phylum_1.txt 
</pre></div>

<h4 id="3-just-get-the-taxa-we-want-from-the-loci">3. just get the taxa we want from the loci<a class="headerlink" href="#3-just-get-the-taxa-we-want-from-the-loci" title="Permanent link"></a></h4>
<div class="highlight"><pre>mkdir -p loci
for loc in ../alignments/*.faa; do
    filename=$(basename $loc)
    faSomeRecords $loc phylum_1.txt loci/${filename}
done

# remove the full alignment, we don&#39;t want that!
rm loci/gtdb_r207_bac120_full.faa 
</pre></div>

<h4 id="4-split-the-loci-between-training-and-testing">4. Split the loci between training and testing<a class="headerlink" href="#4-split-the-loci-between-training-and-testing" title="Permanent link"></a></h4>
<p>Here we choose at random 20 loci for testsing, which leaves 100 for training.</p>
<div class="highlight"><pre>cd loci
mkdir -p training_loci
mkdir -p testing_loci

test_set=$(ls | sort -R | tail -20)

mv $test_set testing_loci
mv *.faa training_loci
cd ..
</pre></div>

<h4 id="5-estimate-the-models">5. Estimate the models<a class="headerlink" href="#5-estimate-the-models" title="Permanent link"></a></h4>
<p>Now we look through all models and estimate the best model for each locus, using the original r207 sub-tree as our tree.</p>
<p>Here we should be careful to set the number of threads equal to (or less than, if necessary) the number of training loci.</p>
<p>This is just a way to keep IQ-TREE efficient (seems silly, and it is, we&rsquo;re working on it!!!).</p>
<p>The following command broken down:</p>
<ul>
<li><code>-T 100</code> 100 threads (I have 100 loci, this will allocate 1 thread to each locus)</li>
<li><code>-p loci/training_loci</code> this points to my folder of 100 training loci, each in its own <code>.faa</code> file</li>
<li><code>-m MFP</code> this calls modelfinder on every locus</li>
<li><code>-cmax 8</code> this allows up to 8 free-rate categories per locus (higher is better, but takes longer)</li>
<li><code>-te phylum_1.tree</code> sets the tree to a pre-estimated tree for these loci (the same tree across all loci)</li>
<li><code>-pre 02_fullcon/iteration_1</code> sets the output directory</li>
</ul>
<div class="highlight"><pre>mkdir 02_fullcon # first make the output directory
iqtree2 -T 100 -p loci/training_loci -m MFP -cmax 8 -te phylum_1.tree -pre 02_fullcon/iteration_1
</pre></div>

<p>The most important output from this is the file <code>iteration_1.best_scheme.nex</code>, which has the best model for each locus in it. </p>
<p>If you scroll through it, you&rsquo;ll see them like this:</p>
<div class="highlight"><pre>  charpartition mymodels =
    LG+F+I+R7: gtdb_r207_bac120_PF00466.21.faa,
    Q.pfam+R6: gtdb_r207_bac120_PF02576.18.faa,
    LG+F+I+R8: gtdb_r207_bac120_TIGR00006.faa,
    LG+F+I+R8: gtdb_r207_bac120_TIGR00019.faa,
    LG+I+R8: gtdb_r207_bac120_TIGR00020.faa,
    rtREV+F+I+R6: gtdb_r207_bac120_TIGR00029.faa,
    LG+F+I+R8: gtdb_r207_bac120_TIGR00054.faa,
    Q.pfam+R8: gtdb_r207_bac120_TIGR00059.faa,
    LG+R6: gtdb_r207_bac120_TIGR00061.faa,
...
</pre></div>

<p>Let&rsquo;s check the models from that analysis:</p>
<p>We can do this with grep and awk&hellip;</p>
<div class="highlight"><pre>grep &#39;^ *[^ ]\+:&#39; 02_fullcon/iteration_1.best_scheme.nex | awk -F: &#39;{print $1}&#39; | awk &#39;{print $NF}&#39; | cut -d&#39;+&#39; -f1 | sort | uniq -c | sort -nr
</pre></div>

<p>This gives us:</p>
<div class="highlight"><pre>     61 LG
     24 Q.pfam
      7 Q.yeast
      6 Q.insect
      1 WAG
      1 rtREV
</pre></div>

<p>Importantly, this tells us that we should use the LG model as the initial model for our analysis, since it&rsquo;s the best fit in 61% of the loci. This means that starting with LG model parameters is likely to be our best bet at getting an even better model.</p>
<h4 id="7-estimate-the-q-matrix">7. Estimate the Q matrix<a class="headerlink" href="#7-estimate-the-q-matrix" title="Permanent link"></a></h4>
<p>Now we estimate the first iteration fo the matrix</p>
<div class="highlight"><pre>iqtree2 -T 100 -S loci/training_loci -p 02_fullcon/iteration_1.best_scheme.nex -te 02_fullcon/iteration_1.treefile --init-model LG --model-joint GTR20+FO -pre 02_fullcon/iteration_1.GTR20
</pre></div>

<p>Once this is done we can do more iterations&hellip;</p>
<h4 id="8-extract-the-q-matrix">8. Extract the Q matrix<a class="headerlink" href="#8-extract-the-q-matrix" title="Permanent link"></a></h4>
<p>Let&rsquo;s get it out and store it away&hellip;</p>
<div class="highlight"><pre>grep -A 21 &quot;can be used as input for IQ-TREE&quot; 02_fullcon/iteration_1.GTR20.iqtree | tail -n20 &gt; Q.bacteria_phylum_1
</pre></div>

<h4 id="9-test-the-new-model-on-the-test-loci">9. Test the new model on the test loci.<a class="headerlink" href="#9-test-the-new-model-on-the-test-loci" title="Permanent link"></a></h4>
<p>Now we want to know how many test loci are best fit by this model. Here I use 20 threads because I only have 20 test loci, and that keeps IQ-TREE efficient. </p>
<p>The general rule is have no more threads than loci.</p>
<p>Here we run IQ-TREE on the test loci, then summarise the output. What we <em>want</em> to see if things worked is that our new matrix is the best for a lot of the test loci!</p>
<div class="highlight"><pre>mkdir 03_testing
iqtree2 -T 20 -S loci/testing_loci/ -m MF -mset LG,Q.pfam,Q.insect,Q.yeast,Q.bacteria_phylum_1 -pre 03_testing/test_loci_mf
grep &#39;^ *[^ ]\+:&#39; 03_testing/test_loci_mf.best_scheme.nex | awk -F: &#39;{print $1}&#39; | awk &#39;{print $NF}&#39; | cut -d&#39;+&#39; -f1 | sort | uniq -c | sort -nr
</pre></div>

<p>This gives:</p>
<div class="highlight"><pre>     19 Q.bacteria_phylum_1
      1 Q.yeast
</pre></div>

<p>This means it worked! The new model is a better fit to the test loci than the old one. And remember, the new model has <em>never</em> seen the test loci before, so it&rsquo;s a legitimate test.</p>
<h4 id="10-test-the-new-model-on-the-whole-dataset">10. Test the new model on the whole dataset<a class="headerlink" href="#10-test-the-new-model-on-the-whole-dataset" title="Permanent link"></a></h4>
<p>Perhaps more importantly, we want to know if the new model fits the BIG tree better. Let&rsquo;s try that too.</p>
<p>Previous analyses (<a href="https://github.com/fredjaya/gtdb_trees/tree/a0d9ce0702487d5ecceb228e36efb208bc6182f9/v0.1.0_analyses/initial_tree_analyses">https://github.com/fredjaya/gtdb_trees/tree/a0d9ce0702487d5ecceb228e36efb208bc6182f9/v0.1.0_analyses/initial_tree_analyses</a>) suggest that we can use raxml-ng for this quite effectively.</p>
<p>We&rsquo;ll try two good rate distributions - +G, and +R4 (there are practically no invariant columns in this data, so I ignore +I models; in addition, the end goal is to work with FastTree which has no +I option). We&rsquo;ll do this on two alignments: the reduced alignment that GTDB use, and the full alignment that they&rsquo;d like to use but don&rsquo;t yet.</p>
<div class="highlight"><pre># QBp1 stands for Q.bacteria_phylum_1
# small alignment
raxml-ng --msa ../alignments/gtdb_r207_bac120_concatenated.faa --model PROTGTR{Q.bacteria_phylum_1}+G --threads 16 --force perf_threads --tree ../r207_original_clean.tree --evaluate --lh-epsilon 0.1  --prefix 03_testing/QBp1G

raxml-ng --msa ../alignments/gtdb_r207_bac120_concatenated.faa --model LG+G --threads 16 --force perf_threads --tree ../r207_original_clean.tree --evaluate --lh-epsilon 0.1  --prefix 03_testing/LG

# big alignment
raxml-ng --msa ../alignments/gtdb_r207_bac120_full.faa --model PROTGTR{Q.bacteria_phylum_1}+G --threads 16 --force perf_threads --tree ../r207_original_clean.tree --evaluate --lh-epsilon 0.1  --prefix 03_testing/QBp1G_full

raxml-ng --msa ../alignments/gtdb_r207_bac120_full.faa --model LG+G --threads 16 --force perf_threads --tree ../r207_original_clean.tree --evaluate --lh-epsilon 0.1  --prefix 03_testing/LGG_full
</pre></div>

<p>Now we want to extract the relevant info from these analyses: likelihoods, AICs, execution times.</p>
<div class="highlight"><pre># Specify your list of filenames
declare -a filenames=(&quot;QBp1G_full.raxml.log&quot; &quot;LGG_full.raxml.log&quot; &quot;QBp1G.raxml.log&quot; &quot;LGG.raxml.log&quot;)

cd 03_testing

# Create a new file to store the table
log_file=&quot;log_table.txt&quot;

# Print the header of the table
echo -e &quot;Likelihood\tAIC\tTime\tFilename&quot; &gt; &quot;$log_file&quot;

# Loop through each specified file
for file in &quot;${filenames[@]}&quot;; do
    # Check if the file exists
    if [[ -f &quot;$file&quot; ]]; then
        # Extract the required values using grep and awk
        likelihood=$(grep &#39;Final LogLikelihood&#39; &quot;$file&quot; | awk &#39;{print $3}&#39;)
        aic=$(grep &#39;AIC score&#39; &quot;$file&quot; | awk &#39;{print $3}&#39;)
        time=$(grep &#39;Elapsed time&#39; &quot;$file&quot; | awk &#39;{print $3}&#39;)
        filename=$(basename &quot;$file&quot;)

        # Append the extracted values to the log file
        echo -e &quot;$likelihood\t$aic\t$time\t$filename&quot; &gt;&gt; &quot;$log_file&quot;
    else
        echo &quot;The file $file does not exist.&quot; &gt;&gt; &quot;$log_file&quot;
    fi
done

# Display the table
cat &quot;$log_file&quot;

cd ..

cat 03_testing/$log_file &gt;&gt; log.txt
</pre></div>

<p>This gives us:</p>
<div class="highlight"><pre>Likelihood      AIC     Time    Filename
-1088000564.208966      2176250288.417933       17965.016       QBp1G_full.raxml.log
-1081479614.701307      2163208389.402613       20892.610       LGG_full.raxml.log
-131190357.878285       262629875.756571        1866.073        QBp1G.raxml.log
-130592049.145638       261433258.291277        3785.556        LGG.raxml.log
</pre></div>

<p>Which is bad news - it shows us that the new matrix fits worse than LG on both the full matrix AND the reduced matrix!</p>
<h3 id="qphylum_1_onemod">Q.phylum_1_onemod<a class="headerlink" href="#qphylum_1_onemod" title="Permanent link"></a></h3>
<p>What if we try without partitions?</p>
<div class="highlight"><pre>iqtree2 -T 100 -s loci/training_loci -m MFP -cmax 8 -mset LG -mrate G -m LG+G -te phylum_1.tree -pre 02_fullcon_onemod/iteration_1

iqtree2 -T 100 -s loci/training_loci -te 02_fullcon/iteration_1.treefile --init-model LG --model-joint GTR20+FO -pre 02_fullcon_onemod/iteration_1.GTR20
</pre></div>

<p>This means that we clearly need an approach that samples differently. Likely the problem here is that the samples are too sparse, so the obvious thing is to sample more densely if we can.</p>
<p>I want to try again with the same phylum dataset, this time bearing in mind the limitation of the end usage. The end usage here is FastTree, which does not cope with partitioned models. Instead, it fits a gamma rate distribution and assumes one model for the whole dataset. We can also try that when estimating the rate matrix, in other words, we constrain all the other parameters so that they match the constraints of the final analysis. Let&rsquo;s see if it makes a difference.</p>
<p>tbc&hellip;</p>
<h3 id="qclass_1">Q.class_1<a class="headerlink" href="#qclass_1" title="Permanent link"></a></h3>
<p>Let&rsquo;s do the same for the class_1.txt list, but this time with a single bash script&hellip;</p>
<h4 id="estimating-it">Estimating it<a class="headerlink" href="#estimating-it" title="Permanent link"></a></h4>
<p>I&rsquo;ll write a very very simple log file as I go, so I can see if things go wrong.</p>
<div class="highlight"><pre>analysis=&quot;class_1&quot;

# 1. set up
mkdir $analysis
cd $analysis

echo &quot;Setting up analysis for &quot;$analysis &gt; log.txt

cp ../$analysis.txt .

# 2. get the subtree (produces $analysis.tree)

echo &quot;Getting subtree for &quot;$analysis&quot;.txt taxon list&quot; &gt;&gt; log.txt

../scripts/get_subtree.py ../r207_original_clean.tree $analysis.txt 


# 3. just get the taxa we want from the loci

echo &quot;Subsetting alignments&quot; &gt;&gt; log.txt

mkdir -p loci
for loc in ../alignments/*.faa; do
    filename=$(basename $loc)
    faSomeRecords $loc $analysis.txt loci/${filename}
done

# remove the full alignment, we don&#39;t want that!
rm loci/gtdb_r207_bac120_full.faa 


# 4. Split the loci between training and testing


echo &quot;splitting alignments into testing and training&quot; &gt;&gt; log.txt

cd loci
test_set=$(ls | sort -R | tail -20)

echo &quot;Test alignments: &quot; &gt;&gt; log.txt
echo $test_set &gt;&gt; log.txt

mkdir -p training_loci
mkdir -p testing_loci


mv $test_set testing_loci
mv *.faa training_loci
cd ..

# check! 

echo &quot;Number of training loci : &quot; &gt;&gt; log.txt
ls loci/training_loci/ | wc -l &gt;&gt; log.txt

echo &quot;Number of testing loci : &quot; &gt;&gt; log.txt
ls loci/testing_loci/ | wc -l &gt;&gt; log.txt

# 5. Estimate the models

echo &quot;Estimating initial models with IQ-TREE2&quot; &gt;&gt; log.txt

mkdir 02_fullcon # first make the output directory
iqtree2 -T 100 -p loci/training_loci -m MFP -cmax 8 -te $analysis.tree -pre 02_fullcon/iteration_1

# get the list of models, and save it to models.txt
grep &#39;^ *[^ ]\+:&#39; 02_fullcon/iteration_1.best_scheme.nex | awk -F: &#39;{print $1}&#39; | awk &#39;{print $NF}&#39; | cut -d&#39;+&#39; -f1 | sort | uniq -c | sort -nr &gt; 02_fullcon/models.txt

echo &quot;List of models best fit to training loci: &quot; &gt;&gt; log.txt
cat 02_fullcon/models.txt &gt;&gt; log.txt

# now we get the init model as the first model in that list

initial_model=$(awk &#39;NR==1 {print $2}&#39; 02_fullcon/models.txt)
echo &quot;Initial Model will be set to&quot; &gt;&gt; log.txt
echo $initial_model &gt;&gt; log.txt

# 7. Estimate the Q matrix

echo &quot;Estimating Q matrix with IQ-TREE2&quot; &gt;&gt; log.txt

iqtree2 -T 100 -S loci/training_loci -p 02_fullcon/iteration_1.best_scheme.nex -te 02_fullcon/iteration_1.treefile --init-model $initial_model --model-joint GTR20+FO -pre 02_fullcon/iteration_1.GTR20
</pre></div>

<p>The final step is the longest, and took ~46 hours, which is not too bad. Now to test it. </p>
<h4 id="testing-it">Testing it<a class="headerlink" href="#testing-it" title="Permanent link"></a></h4>
<p>Let&rsquo;s write another simple bash script for testing&hellip;</p>
<div class="highlight"><pre>analysis=&quot;class_1&quot;

cd $analysis

# extract the matrix
new_model=&quot;Q.bacteria_&quot;$analysis
echo &quot;&quot; &gt;&gt; log.txt
echo &quot;## Model Testing ##&quot; &gt;&gt; log.txt
echo &quot;Extracting model and saving to &quot;$new_model &gt;&gt; log.txt

grep -A 21 &quot;can be used as input for IQ-TREE&quot; 02_fullcon/iteration_1.GTR20.iqtree | tail -n20 &gt; $new_model

cat $new_model &gt;&gt; log.txt

# test it on test loci
echo &quot;&quot;
echo &quot;Testing model on test loci...&quot; &gt;&gt; log.txt
echo &quot;Frequency table of best-fit models&quot; &gt;&gt; log.txt
mkdir 03_testing
iqtree2 -T 20 -S loci/testing_loci/ -m MF -mset LG,Q.pfam,Q.insect,Q.yeast,$new_model -pre 03_testing/test_loci_mf
grep &#39;^ *[^ ]\+:&#39; 03_testing/test_loci_mf.best_scheme.nex | awk -F: &#39;{print $1}&#39; | awk &#39;{print $NF}&#39; | cut -d&#39;+&#39; -f1 | sort | uniq -c | sort -nr &gt;&gt; log.txt

# test it on the full and the reduced datasets
# we don&#39;t need to do LG since we did that for phylum_1...

# small alignment
raxml-ng --msa ../alignments/gtdb_r207_bac120_concatenated.faa --model PROTGTR{$new_model}+G --threads 16 --force perf_threads --tree ../r207_original_clean.tree --evaluate --lh-epsilon 0.1  --prefix 03_testing/$new_model&quot;_G_reduced_aln&quot;

# big alignment
raxml-ng --msa ../alignments/gtdb_r207_bac120_full.faa --model PROTGTR{$new_model}+G --threads 16 --force perf_threads --tree ../r207_original_clean.tree --evaluate --lh-epsilon 0.1  --prefix 03_testing/$new_model&quot;_G_full_aln&quot;

# finally we make a little table of the likelihoods etc. for the analyses, and compare it to LG

# Specify your list of filenames
f1=$new_model&quot;_G_reduced_aln.raxml.log&quot;
f2=&quot;../../phylum_1/03_testing/LGG.raxml.log&quot;
f3=$new_model&quot;_G_full_aln.raxml.log&quot;
f4=&quot;../../phylum_1/03_testing/LGG_full.raxml.log&quot;
declare -a filenames=($f1 $f2 $f3 $f4)

cd 03_testing

# Create a new file to store the table
log_file=&quot;log_table.txt&quot;

# Print the header of the table
echo -e &quot;Likelihood\tAIC\tTime\tFilename&quot; &gt; &quot;$log_file&quot;

# Loop through each specified file
for file in &quot;${filenames[@]}&quot;; do
    # Check if the file exists
    if [[ -f &quot;$file&quot; ]]; then
        # Extract the required values using grep and awk
        likelihood=$(grep &#39;Final LogLikelihood&#39; &quot;$file&quot; | awk &#39;{print $3}&#39;)
        aic=$(grep &#39;AIC score&#39; &quot;$file&quot; | awk &#39;{print $3}&#39;)
        time=$(grep &#39;Elapsed time&#39; &quot;$file&quot; | awk &#39;{print $3}&#39;)
        filename=$(basename &quot;$file&quot;)

        # Append the extracted values to the log file
        echo -e &quot;$likelihood\t$aic\t$time\t$filename&quot; &gt;&gt; &quot;$log_file&quot;
    else
        echo &quot;The file $file does not exist.&quot; &gt;&gt; &quot;$log_file&quot;
    fi
done

# Display the table
cat &quot;$log_file&quot;

cd ..

cat 03_testing/$log_file &gt;&gt; log.txt
</pre></div>

<p>The results for this show that this matrix doesn&rsquo;t work either (though it&rsquo;s still better than the phylum level matrix)</p>
<p>Combining the results tables&hellip;</p>
<div class="highlight"><pre>Likelihood      AIC     Time    Filename
-131190357.878285       262629875.756571        1866.073        QBp1G.raxml.log
-131099420.890135       262448001.780271        1442.474        Q.bacteria_class_1_G_reduced_aln.raxml.log
-130592049.145638       261433258.291277        3785.556        LGG.raxml.log
-1088000564.208966      2176250288.417933       17965.016       QBp1G_full.raxml.log
-1086808724.440440      2173866608.880880       12427.577       Q.bacteria_class_1_G_full_aln.raxml.log
-1081479614.701307      2163208389.402613       20892.610       LGG_full.raxml.log
-1078809634.619930      2157868429.239860       11799.372       Q.GTDB_sub_5k_G_full_aln.raxml.log
</pre></div>

<h3 id="qorder_1">Q.order_1<a class="headerlink" href="#qorder_1" title="Permanent link"></a></h3>
<p>Now let&rsquo;s start a matrix running which is estimated by order. To do this, I&rsquo;ll save the above as a bash script called <code>order_1.sh</code>, change the first line to</p>
<div class="highlight"><pre>analysis=&quot;order_1&quot;
</pre></div>

<p>These alignments are big, and estimating models will be very expensive (particularly free rate models).</p>
<p>So I&rsquo;ll also look at just four models here, based on the previous analyses, by changing the script to:</p>
<div class="highlight"><pre>model_set=&quot;LG,Q.pfam,Q.insect,Q.yeast&quot;

mkdir 02_fullcon # first make the output directory
iqtree2 -T 100 -p loci/training_loci -m MFP -cmax 8 -mset $model_set -te $analysis.tree -pre 02_fullcon/iteration_1
</pre></div>

<p>I chose these models because in the phylum level analysis they represented 98% of genes, and in the class-level analysis they represented 100% of genes.</p>
<p>Now I can just set it running with</p>
<div class="highlight"><pre>bash order_1.sh
</pre></div>

<p>And now we can test it with the testing script above after changing the first line to:</p>
<div class="highlight"><pre>analysis=&quot;order_1&quot;
</pre></div>

<h3 id="qfamily_1">Q.family_1<a class="headerlink" href="#qfamily_1" title="Permanent link"></a></h3>
<p>Can we estimate a matrix with one genome per family? In the subset dataset there are 2570, which is about 2.5x bigger than the order level dataset. One way to guess how long this will take is to look at the previous runs sizes and execution times.</p>
<p><div class="highlight"><pre>times &lt;- tibble(
  matrix = c(&quot;Q.order_1&quot;, &quot;Q.class_1&quot;, &quot;Q.phylum_1&quot;),
  time_hrs = c(87, 46, 16),
  taxa = c(1090, 343, 140)
)
</pre></div>
Encouragingly, this is sub-linear. So we can guesstimate that the family level matrix will take 2.5x 87hrs, which is ~220 hrs or 10 days. </p>
<p>Let&rsquo;s try. </p>
<div class="highlight"><pre>family_1 &lt;- subset %&gt;%
    group_by(family) %&gt;%
    sample_n(1) %&gt;%
    ungroup() %&gt;%
    pull(id)
writeLines(family_1, &quot;family_1.txt&quot;)
</pre></div>

<h3 id="qgenus_1">Q.genus_1<a class="headerlink" href="#qgenus_1" title="Permanent link"></a></h3>
<p>Let&rsquo;s also try one per genus, just for fun</p>
<div class="highlight"><pre>genus_1 &lt;- subset %&gt;%
    group_by(genus) %&gt;%
    sample_n(1) %&gt;%
    ungroup() %&gt;%
    pull(id)
writeLines(genus_1, &quot;genus_1.txt&quot;)
</pre></div>

<h2 id="qgtdb_sub-estimate-q-matrices-from-subtrees">Q.GTDB_sub: Estimate Q Matrices from subtrees<a class="headerlink" href="#qgtdb_sub-estimate-q-matrices-from-subtrees" title="Permanent link"></a></h2>
<h3 id="splitting-into-subtrees">Splitting into subtrees<a class="headerlink" href="#splitting-into-subtrees" title="Permanent link"></a></h3>
<p>The matrices above eventually worked, but I suspect we can do more. </p>
<p>We can try to include many more of the branches near the tips, by splitting the input tree into a series of subtrees, where each subtree is some maximum size. There&rsquo;s a tradeoff here, because we will lose taxa on trees with &lt;4 species. However, it&rsquo;s an empirical question as to how much that matters, and the first challenge is to be able to split the input tree into subtrees at all. </p>
<p>Let&rsquo;s start with an algorithm to split the big tree into smaller ones:</p>
<div class="highlight"><pre>library(castor)

split_tree &lt;- function(tree, Nmax = 1000, Nmin = 4){

  to_split = list(tree)
  to_keep = list() # we&#39;ll put trees to keep here

  # we don&#39;t need to do anything if the input tree is already small enough  
  if(Ntip(tree)&lt;=N){
    return(c(tree))
  }

  while(length(to_split)&gt;0){

    cat(&quot;to split: &quot;, length(to_split), &quot;    to keep: &quot;, length(to_keep), &quot;\n&quot;)

    # poor man&#39;s pop: get the first element and delete it
    t = to_split[[1]]
    to_split[[1]] &lt;- NULL

    # split the tree (this is effectively just splitting it at the root node of the tree)
    splits &lt;- split_tree_at_height(t, 0.00000000000000000000000000000001)
    # extract the subtrees from the castor object
    subtrees = sapply(splits$subtrees, function(x) x$tree, simplify = FALSE)

    for(subtree in subtrees){

      if( Ntip(subtree) &gt; Nmax ){ # split it again...
        to_split[[length(to_split) + 1]] &lt;- subtree
      } else if ( Ntip(subtree) &gt; (Nmin - 1)){ # it&#39;s between 4 and N, which is what we want
        to_keep[[length(to_keep) + 1]] &lt;- subtree
      } 
      # otherwise we ditch the tree because it has &lt;=3 tips
    }
  }

  class(to_keep) &lt;- &#39;multiPhylo&#39;
  return(to_keep)
}
</pre></div>

<p>This works up from the root, and keep splitting subtrees when they are bigger than the maximum value. It keeps any subtree which is smaller than the maximum value but at least as big as the minimum.</p>
<p>For example, we can run it on the big tree like so:</p>
<div class="highlight"><pre>tree &lt;- read.tree(r207_original_clean.tree)
subtrees &lt;- split_tree(tree, 100, 20)
</pre></div>

<p>This gives 970 trees, which have quite a uniform distribution of sizes from 20 to 100
Remarkably, they include 55517 of the 62291 taxa, or about 90%. The tree lengths are also sensible:</p>
<div class="highlight"><pre>tree_lengths &lt;- sapply(subtrees, function(tree) sum(tree$edge.length))
#&gt; summary(tree_lengths)
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 0.1692  2.3551  4.4316  5.9376  7.8711 40.0413 
</pre></div>

<p>A challenge here is that we now have 970 subtrees (a little bit less when we use the filtered dataset). Since we have 120 genes, that means we have of the order of 100,000 alignments. That&rsquo;s a lot! The smart thing to do here is probably to treat this as its own empirical problem. How many do we need to estimate a good matrix? </p>
<p>One approach is to first make the 100K alignments, and then to try various training set sizes and look at the characteristics of the resulting matrix.</p>
<p>Let&rsquo;s go!</p>
<h3 id="creating-the-sub-alignments-and-sub-trees">Creating the sub-alignments and sub-trees<a class="headerlink" href="#creating-the-sub-alignments-and-sub-trees" title="Permanent link"></a></h3>
<p>First we get the subtrees only from the subset of taxa we actually care about (recall above that we removed taxa with a lot of gaps, and those on long branches).</p>
<div class="highlight"><pre>tree &lt;- read.tree(&quot;r207_original_clean.tree&quot;)

to_keep = subset$id

subtree = get_subtree_with_tips(tree, only_tips = to_keep)$subtree
</pre></div>

<p>No we subdivide that subtree into trees of 20-100 taxa.</p>
<div class="highlight"><pre>subtrees &lt;- split_tree(subtree, 100, 20)
</pre></div>

<p>Check the distributions</p>
<div class="highlight"><pre>tree_lengths &lt;- sapply(subtrees, function(tree) max(tree$edge.length))
tips &lt;- sapply(subtrees, function(tree) Ntip(tree))
summary(tree_lengths)
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#0.00752 0.11794 0.20503 0.24104 0.31827 0.85776 
summary(tips)
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
#  20.00   34.00   53.00   56.35   79.00  100.00 
</pre></div>

<p>The trees contain a total of 37921 tips. That&rsquo;s 90% of the input tree, or 60% of the original dataset. </p>
<p>Now let&rsquo;s export those trees, and their taxon lists.</p>
<div class="highlight"><pre>mkdir Q.GTDB_sub
</pre></div>

<div class="highlight"><pre>write_trees_and_taxa &lt;- function(multiphylo_trees, folder_path) {
  for (i in seq_along(multiphylo_trees)) {
    # Format the file names with leading zeros
    tree_file_name &lt;- sprintf(&quot;%03d.tree&quot;, i)
    taxa_file_name &lt;- sprintf(&quot;%03d.txt&quot;, i)

    # Write the tree to file
    write.tree(multiphylo_trees[[i]], file.path(folder_path, tree_file_name))

    # Write the taxon list to file
    taxa &lt;- multiphylo_trees[[i]]$tip.label
    writeLines(taxa, con = file.path(folder_path, taxa_file_name))
  }
}

# Usage: replace &quot;path/to/folder&quot; with the desired folder path
write_trees_and_taxa(subtrees, &quot;Q.GTDB_sub&quot;)
</pre></div>

<h3 id="building-the-q-matrix">Building the Q matrix<a class="headerlink" href="#building-the-q-matrix" title="Permanent link"></a></h3>
<p>THe script for building the Q matrix will be quite different in places. Here it is</p>
<div class="highlight"><pre>analysis=&quot;Q.GTDB_sub&quot;

echo &quot;Setting up analysis for &quot;$analysis &gt; log.txt

# 3. just get the taxa we want from the loci

echo &quot;Subsetting alignments&quot; &gt;&gt; log.txt

mkdir -p loci
for taxon_list in taxon_lists/*.txt; do

    base_name=$(basename &quot;$taxon_list&quot; .txt)

    for loc in ../alignments/*.faa; do
        filename=$(basename $loc)
        new_filename=&quot;${base_name}_${filename}&quot;

        faSomeRecords $loc $taxon_list loci/${new_filename}

    done
done

echo &quot;&quot; &gt;&gt; log.txt
echo &quot;Sub-alignments created for each gene and taxon list.&quot; &gt;&gt; log.txt
alignment_count=$(find loci/ -name &quot;*.faa&quot; | wc -l)
echo &quot;A total of $alignment_count alignments were created.&quot; &gt;&gt; log.txt
</pre></div>

<p>Next we&rsquo;ll determine 1000 testing loci, and then we&rsquo;ll start with 1000 training loci. I&rsquo;ll make a series of training folders, so that I can train a number of matrices using different sized training datasets.</p>
<div class="highlight"><pre># 4. Split the loci between training and testing

echo &quot;splitting alignments into testing and training&quot; &gt;&gt; log.txt


test_set=$(ls loci | sort -R | tail -1000)

echo &quot;Test alignments: &quot; &gt;&gt; log.txt
echo $test_set &gt;&gt; log.txt
mkdir -p testing_loci
for file in $test_set; do
    mv &quot;loci/$file&quot; testing_loci/
done

# now we need to de-duplicate the remaining loci. No training comes from duplicates...
# we then remove any files with &lt;10 sequences
# we also remove any sequences that are all gaps

mkdir loci_deduped
mkdir loci_clean
for file in loci/*; do
    fname=$(basename $file)
    seqkit rmdup --by-seq -o loci_deduped/$fname $file
    seqkit grep -w 0 -svrp &quot;^-+$&quot; loci_deduped/$fname &gt; loci_clean/$fname # remove sequences that are all gaps
    nseq=$(grep -c &#39;&gt;&#39; loci_clean/$fname)  # -c will count the number of matches
    echo &quot;$nseq sequences left&quot;
    if [ &quot;$nseq&quot; -lt 10 ]; then
        rm loci_clean/$fname
    fi    
done

# clean up!
rm -rf loci_deduped

mkdir -p training_loci_100 # for testing!
mkdir -p training_loci_1k
mkdir -p training_loci_5k
mkdir -p training_loci_10k
mkdir -p training_loci_50k
training_set100=$(ls loci_clean | sort -R | tail -100)
training_set1k=$(ls loci_clean | sort -R | tail -1000)
training_set5k=$(ls loci_clean | sort -R | tail -5000)
training_set10k=$(ls loci_clean | sort -R | tail -10000)
training_set50k=$(ls loci_clean | sort -R | tail -50000)

for file in $training_set100; do 
    cp &quot;loci_clean/$file&quot; training_loci_100/
done


for file in $training_set1k; do 
    cp &quot;loci_clean/$file&quot; training_loci_1k/
done

for file in $training_set5k; do 
    cp &quot;loci_clean/$file&quot; training_loci_5k/
done

for file in $training_set10k; do 
    cp &quot;loci_clean/$file&quot; training_loci_10k/
done

for file in $training_set50k; do 
    cp &quot;loci_clean/$file&quot; training_loci_50k/
done




# check! 

echo &quot;&quot; &gt;&gt; log.txt
echo &quot;Number of testing loci : &quot; &gt;&gt; log.txt
ls testing_loci/ | wc -l &gt;&gt; log.txt

echo &quot;&quot; &gt;&gt; log.txt
echo &quot;Number of training loci : &quot; &gt;&gt; log.txt
alignment_count=$(find loci/ -name &quot;*.faa&quot; | wc -l)

n100=$(find training_loci_100/ -name &quot;*.faa&quot; | wc -l)
n1k=$(find training_loci_1k/ -name &quot;*.faa&quot; | wc -l)
n5k=$(find training_loci_5k/ -name &quot;*.faa&quot; | wc -l)
n10k=$(find training_loci_10k/ -name &quot;*.faa&quot; | wc -l)
n50k=$(find training_loci_50k/ -name &quot;*.faa&quot; | wc -l)
echo &quot;training_loci_100: $n100&quot; &gt;&gt; log.txt
echo &quot;training_loci_1k: $n1k&quot; &gt;&gt; log.txt
echo &quot;training_loci_5k: $n5k&quot; &gt;&gt; log.txt
echo &quot;training_loci_10k: $n10k&quot; &gt;&gt; log.txt
echo &quot;training_loci_50k: $n50k&quot; &gt;&gt; log.txt
</pre></div>

<p>Now we estimate the models, but we need to do this once for every training dataset.</p>
<p>This is initially stored in <code>Q.GTDB_sub_5k.sh</code></p></article></body></html>